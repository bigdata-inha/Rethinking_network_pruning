# Rethinking network pruning from the perspective of learning rate decay methods

Thinet(option : greedy) paper : ThiNet: A Filter Level Pruning Method for Deep Neural Network Compression(ICCV,2017)

LASSO(option : lasso) paper: Channel Pruning for Accelerating Very Deep Neural Networks(ICCV,2017)

# Prerequistes
1. pytorch, python : pytorch 1.6 ↑, python 3.7 ↑
2. package : numpy, os, torchsummaryX, tqdm

## have to download VGG16_BN weight and then move model weights to directory './experiments/vgg16_exp_cifar100_0/checkpoints/' 

https://drive.google.com/drive/folders/1D0zxgCMg3nDUGGxCt8n2PDtcU6FHVysP?usp=sharing


# Experiments
<img src="https://user-images.githubusercontent.com/46774714/101134388-a3000000-364d-11eb-87f1-90ed39c8e611.jpg" width="100%" height="90%">


<img src="https://user-images.githubusercontent.com/46774714/101134513-d773bc00-364d-11eb-83e3-4a8bba9454b4.jpg" width="100%" height="90%">
